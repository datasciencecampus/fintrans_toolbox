{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a847bc16-622e-4de0-b0de-4e229ca5f8d5",
   "metadata": {},
   "source": [
    "# Calculate unknown unknowns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b040e44-d784-4160-a94d-6babac2eb45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_path = \"/home/jupyter\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(project_path)\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import geopandas as gpd\n",
    "from plotly import graph_objs as go\n",
    "import seaborn as sns\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cmath as math\n",
    "\n",
    "from fintrans_toolbox.src import bq_utils as bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6902b55-2cec-435e-858c-473586d75951",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da23573-0312-441b-a750-0be27b1e1936",
   "metadata": {},
   "source": [
    "# specify filters\n",
    "here you can specify which dataset you wish to produce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2362624-cc92-4bb2-b686-0aca315d130e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = '`ons-fintrans-data-prod.fintrans_visa.retail_performance_high_streets_towns-2024-01-16T17_11_35`'\n",
    "time_period = 'Quarter'\n",
    "location_level = 'POSTAL_AREA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024d35c-81fc-4675-8d14-730ed967c052",
   "metadata": {},
   "source": [
    "# Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bac1ad-5800-4f88-b2e1-fa024dc8d742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sql_query(table, time_period, \n",
    "                     cardholder_location_level, \n",
    "                     merchant_location_level):\n",
    "    '''Create a SQL query for a given time period, cardholder location level\n",
    "    and merchant location level.\n",
    "    \n",
    "    Args:\n",
    "        time_period (str): 'Month' or 'Quarter'\n",
    "        cardholder_location_level (str): 'POSTAL_DISTRICT', 'POSTAL AREA' \n",
    "            or 'All'\n",
    "        merchant_location_level (str): 'POSTAL_DISTRICT', 'POSTAL AREA' \n",
    "            or 'All'\n",
    "    Returns:\n",
    "        Str: a string containing the desired SQL query\n",
    "    '''\n",
    "    time_period_values = ['Month', 'Quarter']\n",
    "    if time_period not in time_period_values:\n",
    "        raise ValueError(\n",
    "            f'Argument time_period must be one of {time_period_values}'\n",
    "        )\n",
    "    location_values = ['POSTAL_DISTRICT', 'POSTAL_AREA', 'All']\n",
    "    if cardholder_location_level not in location_values:\n",
    "        raise ValueError(\n",
    "            f'Argument cardholder_location_level must be one of {location_values}'\n",
    "        )\n",
    "    if merchant_location_level not in location_values:\n",
    "        raise ValueError(\n",
    "            f'Argument merchant_location_level must be one of {location_values}'\n",
    "        )\n",
    "    \n",
    "    sql = f'''SELECT DISTINCT time_period_value, \n",
    "           cardholder_location, \n",
    "           merchant_location, \n",
    "           sum(spend) as sum_spend \n",
    "           FROM {table} \n",
    "           WHERE time_period = '{time_period}' \n",
    "           AND cardholder_location_level = '{cardholder_location_level}' \n",
    "           AND merchant_location_level = '{merchant_location_level}' \n",
    "           AND mcg = 'All' \n",
    "           GROUP BY time_period_value, cardholder_location, merchant_location \n",
    "           ORDER BY time_period_value, cardholder_location'''\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3909ab-9778-4e0b-8c9e-c58d2f630c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_in_data(sql):\n",
    "    '''Read in data. Convert the time_period_value to pd.Categorical\n",
    "    datatype to save memory.\n",
    "    \n",
    "    Args: \n",
    "        sql (str): SQL query to select the desired data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''\n",
    "    \n",
    "    data = bq.read_bq_table_sql(client, sql)\n",
    "    data['time_period_value'] = pd.Categorical(data['time_period_value'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93868fdb-0b2c-4448-953c-42d00bbcc857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_postal_areas(df):\n",
    "    '''Function to remove locations that have been incorrectly labelled as a \n",
    "    given postal district from the dataset based on the NSPL dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['numbers'] =  (\n",
    "        df['merchant_location'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "    )\n",
    "    postal_areas = (\n",
    "        (df['merchant_location'] != 'UNKNOWN') \n",
    "        & (df['merchant_location'] != 'All')\n",
    "        & (df['numbers'] == 0)\n",
    "    )\n",
    "    df.loc[postal_areas,['merchant_location']] = 'UNKNOWN'\n",
    "    df = df.drop('numbers', axis = 1)\n",
    "    \n",
    "    df = df.groupby(\n",
    "        ['time_period_value', \n",
    "        'cardholder_location', \n",
    "        'merchant_location'],\n",
    "        observed=True\n",
    "    )['sum_spend'].sum().reset_index()\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec14f4-2adb-4a84-905e-af05a6da0aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_locations_to_categorical(df):\n",
    "    '''Convert the locations from strings to PandasCatagorical datatype. This \n",
    "    is to save memory.\n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame)\n",
    "    \n",
    "    Returns:\n",
    "     pd.DataFrame\n",
    "    '''\n",
    "    \n",
    "    df_map = df.copy()\n",
    "    # convert location strings to pandas.Catagorical\n",
    "    df_map['cardholder_location'] = df_map['cardholder_location'].astype('category')\n",
    "    df_map['merchant_location'] = df_map['merchant_location'].astype('category')\n",
    "\n",
    "    # ensure both columns share the same mapping\n",
    "    category_mapping = df_map['cardholder_location'].cat.categories\n",
    "    df_map['merchant_location'] = df_map['merchant_location'].cat.set_categories(category_mapping)\n",
    "    \n",
    "    return df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8af6e8-9509-4eca-9d9a-7a71125b9286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_location_mapping_columns(df):\n",
    "    '''Create columns populated with the numerical representations of the \n",
    "    location columns.\n",
    "    \n",
    "    Args: df (pd.DataFrame)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''\n",
    "    df_map = df.copy()\n",
    " \n",
    "    df_map['cardholder_location_code'] = df_map['cardholder_location'].cat.codes\n",
    "    df_map['merchant_location_code'] = df_map['merchant_location'].cat.codes\n",
    "   \n",
    "    return df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551633c-a6fa-43bd-8764-fe7f76a7098c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lookup_table(df):\n",
    "    '''create a lookup table which maps the postal districts to their numerical\n",
    "    representations.\n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame): dataframe with location columns in pd.Categorical\n",
    "            format\n",
    "    \n",
    "    Returns: \n",
    "        pd.DataFrame\n",
    "    '''\n",
    "    category_mapping = df['cardholder_location'].cat.categories\n",
    "\n",
    "    lookup_table = pd.DataFrame({\n",
    "        'postal_district': category_mapping,\n",
    "        'postal_district_code': range(len(category_mapping))\n",
    "    })\n",
    "    return lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddc485-522e-45ef-af82-fa4ce00f0c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_data(sql):\n",
    "    '''Read in data. Convert the time_period_value to a datetime for easier \n",
    "    manipulation and to save memory. If importing postal district data, remove \n",
    "    postal areas that have been incorrectly labelled.\n",
    "    \n",
    "    Args:\n",
    "        sql (str): sql query for the data you are reading in.\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    df = read_in_data(sql)\n",
    "    if 'POSTAL_DISTRICT' in sql:\n",
    "        df = remove_postal_areas(df)\n",
    "        print('''remove_postal_areas used. YOU SHOULD NOT SEE THIS IF YOU \n",
    "        ARE LOOKING AT POSTAL AREAS!!!''')\n",
    "    else:\n",
    "        print('''remove_postal_areas function NOT used. You SHOULD see this if\n",
    "        you are looking at postal areas or at the all_all breakdown.''')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb381e-1d98-4d8f-8c58-e26af61494d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_unknowns_stage_1(cardholder_merchant, cardholder_all):\n",
    "    ''' compare the data where we have cardholder location and merchant\n",
    "    location to the data where we have cardholder location but merchant \n",
    "    location is set to 'All'\n",
    "    '''\n",
    "    \n",
    "    grouped_cardholder_merchant =  cardholder_merchant.groupby(\n",
    "        ['time_period_value', 'cardholder_location'],\n",
    "        observed=True\n",
    "    )['sum_spend'].sum().reset_index()\n",
    "    \n",
    "    cardholder_all = cardholder_all.drop(\n",
    "    columns='merchant_location'\n",
    "    )\n",
    "    \n",
    "    unknown = cardholder_all.merge(\n",
    "        grouped_cardholder_merchant, \n",
    "        on=('time_period_value', 'cardholder_location'), \n",
    "        how='outer', \n",
    "        suffixes=('_cardholder_all', '_cardholder_merchant')\n",
    "    )\n",
    "    \n",
    "    # for the case below we have data in the district_district dataframe but not the \n",
    "    # district_all dataframe. so there are NO unknowns being added to the \n",
    "    # district_district dataframe from the district_all data (these are cases where \n",
    "    # we have more data in the district_district data). \n",
    "    # here we swap the data between columns so we are keeping this data when\n",
    "    # using the calculations in the following cells.\n",
    "    mask = unknown['sum_spend_cardholder_all'].isnull()\n",
    "    unknown.loc[\n",
    "        mask, \n",
    "        ['sum_spend_cardholder_all', 'sum_spend_cardholder_merchant']\n",
    "    ] = unknown.loc[\n",
    "        mask,\n",
    "        ['sum_spend_cardholder_merchant', 'sum_spend_cardholder_all']\n",
    "    ].values\n",
    "    \n",
    "    # after the swap we can fill the NaN values with '0'. so we will be subtracting \n",
    "    # 0 in the calculations in the following cells.\n",
    "    # We fill with a '0' because the postal area is present \n",
    "    # in the district_all dataframe but not the district_district dataframe. \n",
    "    # so we can say that there is '0' known spend in the district_district \n",
    "    # dataframe.\n",
    "    # We also have the data above, where the columns have been switched, this \n",
    "    # is explained above.\n",
    "    unknown['sum_spend_cardholder_merchant'] = (\n",
    "        unknown['sum_spend_cardholder_merchant'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    unknown['sum_spend'] = (\n",
    "        unknown['sum_spend_cardholder_all'] - \n",
    "        unknown['sum_spend_cardholder_merchant']\n",
    "    )\n",
    "    unknown['merchant_location'] = 'UNKNOWN'\n",
    "\n",
    "    unknown = unknown[['time_period_value', \n",
    "                       'cardholder_location', \n",
    "                       'merchant_location',\n",
    "                       'sum_spend']]\n",
    "\n",
    "    combined_data = pd.concat([cardholder_merchant, unknown], axis=0, ignore_index=True)\n",
    "    \n",
    "    combined_data =  combined_data.groupby(\n",
    "        ['time_period_value', 'cardholder_location', 'merchant_location'],\n",
    "        observed=True\n",
    "    )['sum_spend'].sum().reset_index()\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68a365-862f-4de4-a374-cc2a625fff6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_unknowns_stage_2(stage_1, all_all):\n",
    "    '''compare the dataframe created from stage 1 of the calculated unknows \n",
    "    with the data where we set cardholder location to all and merchant\n",
    "    location to all.\n",
    "    '''\n",
    "    \n",
    "    stage_1_time_grouped = (\n",
    "        stage_1.groupby(\n",
    "            'time_period_value', \n",
    "            observed=True\n",
    "        )['sum_spend'].sum().reset_index()\n",
    "    )\n",
    "    \n",
    "    unknowns = stage_1_time_grouped.merge(\n",
    "        all_all, \n",
    "        on='time_period_value',\n",
    "        suffixes=('_district_district', '_all_all')\n",
    "    )\n",
    "    \n",
    "    unknowns['sum_spend'] = (\n",
    "        unknowns['sum_spend_all_all'] \n",
    "        - unknowns['sum_spend_district_district']\n",
    "    )\n",
    "    \n",
    "    unknowns['cardholder_location'] = 'UNKNOWN'\n",
    "    unknowns['merchant_location'] = 'UNKNOWN'\n",
    "    \n",
    "    unknowns = unknowns[['time_period_value', \n",
    "                         'cardholder_location', \n",
    "                         'merchant_location', \n",
    "                         'sum_spend']]\n",
    "    \n",
    "    combined_data = pd.concat([stage_1, unknowns], \n",
    "                              axis=0, \n",
    "                              ignore_index=True)\n",
    "    \n",
    "    combined_data =  combined_data.groupby(\n",
    "        ['time_period_value', 'cardholder_location', 'merchant_location'],\n",
    "        observed=True\n",
    "    )['sum_spend'].sum().reset_index()\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6598fd9-ec72-4947-bf0c-5877d4e23dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_unknowns_stage_3(stage_2, all_merchant):\n",
    "    '''compare the output of calculate unknowns stage 2 to fill in the extra\n",
    "    information from the data where we have merchant location but we set \n",
    "    cardholder location to 'All'\n",
    "    '''\n",
    "    \n",
    "    stage_2_time_grouped = stage_2.groupby(\n",
    "        ['time_period_value', 'merchant_location'],\n",
    "        observed=True\n",
    "    )['sum_spend'].sum().reset_index()\n",
    "    \n",
    "    stage_2_time_grouped['cardholder_location'] = 'All'\n",
    "    \n",
    "    all_merchant_merged = all_merchant.merge(\n",
    "        stage_2_time_grouped,\n",
    "        on=['time_period_value', 'cardholder_location', 'merchant_location'],\n",
    "        how='outer',\n",
    "        suffixes=('_all_merchant', '_stage_2')\n",
    "    )\n",
    "    \n",
    "    missing_rows = all_merchant_merged[\n",
    "        all_merchant_merged['sum_spend_stage_2'].isnull()\n",
    "    ]\n",
    "    missing_rows_time_grouped = missing_rows.groupby(\n",
    "        'time_period_value',\n",
    "        observed=True\n",
    "    )['sum_spend_all_merchant'].sum().reset_index()\n",
    "    \n",
    "    unknown_unknown = stage_2[\n",
    "        (stage_2['cardholder_location'] == 'UNKNOWN')\n",
    "        & (stage_2['merchant_location'] == 'UNKNOWN')\n",
    "    ]\n",
    "\n",
    "    comparisson_missing_rows = unknown_unknown.merge(\n",
    "        missing_rows_time_grouped,\n",
    "        on=['time_period_value'],\n",
    "        suffixes=('_stage_2', '_all_merchant')\n",
    "    )\n",
    "    \n",
    "    comparisson_missing_rows['sum_spend_stage_2'] = (\n",
    "        comparisson_missing_rows['sum_spend']\n",
    "        - comparisson_missing_rows['sum_spend_all_merchant']\n",
    "    )\n",
    "    \n",
    "    unknown_unknown_updated = comparisson_missing_rows[\n",
    "        ['time_period_value', \n",
    "         'cardholder_location', \n",
    "         'merchant_location', \n",
    "         'sum_spend_stage_2']\n",
    "    ].copy()\n",
    "    unknown_unknown_updated.columns = (\n",
    "        unknown_unknown_updated.columns.str.replace('_stage_2', '')\n",
    "    )\n",
    "    \n",
    "    stage_2_unknown_updated = stage_2.merge(\n",
    "        unknown_unknown_updated,\n",
    "        on=['time_period_value',\n",
    "            'cardholder_location',\n",
    "            'merchant_location'],\n",
    "        how='outer',\n",
    "        suffixes=('_original', '_updated')\n",
    "    )\n",
    "\n",
    "    stage_2_unknown_updated['sum_spend'] = (\n",
    "        stage_2_unknown_updated['sum_spend_updated'].fillna(\n",
    "            stage_2_unknown_updated['sum_spend_original']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    stage_2_unknown_updated.drop(\n",
    "        columns=['sum_spend_original', 'sum_spend_updated'], inplace=True\n",
    "    )\n",
    "    \n",
    "    new_unknown_merchant = missing_rows[\n",
    "        ['time_period_value', \n",
    "         'cardholder_location', \n",
    "         'merchant_location', \n",
    "         'sum_spend_all_merchant']\n",
    "    ].copy()\n",
    "    \n",
    "    new_unknown_merchant['cardholder_location'] = 'UNKNOWN'\n",
    "    new_unknown_merchant = new_unknown_merchant.rename(\n",
    "        columns={'sum_spend_all_merchant': 'sum_spend'}\n",
    "    )\n",
    "\n",
    "    complete_dataset = pd.concat(\n",
    "        [stage_2_unknown_updated, new_unknown_merchant],\n",
    "         axis=0,\n",
    "         ignore_index=True\n",
    "    )\n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbabc8-77ed-4558-a9b9-241d8fb0fa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_unknowns(cardholder_district, cardholder_all, all_merchant, all_all):\n",
    "    '''Run all the stages of the unknown calculations to fill in all the missing\n",
    "    unknown unknowns.\n",
    "    '''\n",
    "    \n",
    "    stage_1 = calculate_unknowns_stage_1(cardholder_district, cardholder_all)\n",
    "    stage_2 = calculate_unknowns_stage_2(stage_1, all_all)\n",
    "    complete_dataset = calculate_unknowns_stage_3(stage_2, all_merchant)\n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e50d6d-5389-450b-aea4-45c929de7849",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data\n",
    "---\n",
    "\n",
    "**For the dataframe variable names will use the following convention thoughout:** \n",
    "\n",
    "* **cardholder_merchant** signifies we have cardholder location data at location level and merchant location data at a location level. \n",
    "* **cardholder_all** signifies we have cardholder location data at a location level but the merchant location is set to 'all'.\n",
    "* **all_merchant** signifies we have set cardholder location to 'All' but the merchant location is at a location level.\n",
    "* **all_all** signifies we have set cardholder and merchant locations to 'All'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779e3bb-ecf0-480f-b5cf-f16e5231cab1",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307ae9b-ebd3-4518-a83c-8d6bce68f707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_cardholder_merchant = create_sql_query(\n",
    "    table=table, \n",
    "    time_period=time_period, \n",
    "    cardholder_location_level = location_level,\n",
    "    merchant_location_level = location_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a17928-53ef-487c-be01-4e6e85a810a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_cardholder_all = create_sql_query(\n",
    "    table=table, \n",
    "    time_period=time_period, \n",
    "    cardholder_location_level = location_level,\n",
    "    merchant_location_level = 'All'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167ddea-e6ee-479f-a2df-e13399e287d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_all_all = create_sql_query(\n",
    "    table=table, \n",
    "    time_period=time_period, \n",
    "    cardholder_location_level = 'All',\n",
    "    merchant_location_level = 'All'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a256f4-421b-4d59-ad6c-cdc9c7354ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_all_merchant = create_sql_query(\n",
    "    table=table, \n",
    "    time_period=time_period, \n",
    "    cardholder_location_level = 'All',\n",
    "    merchant_location_level = location_level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa1768-d80b-4d62-a50a-5e08afeecd0e",
   "metadata": {},
   "source": [
    "## Create dataframes (with mislabelled merchant postal districts converted to unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c2f26-318c-496e-8e7c-d3cba4b5fabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_all = import_data(sql_all_all)\n",
    "all_merchant = import_data(sql_all_merchant)\n",
    "cardholder_all = import_data(sql_cardholder_all)\n",
    "cardholder_merchant = import_data(sql_cardholder_merchant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517cb22-e1f8-4cbb-b2b0-ececcb0e20fd",
   "metadata": {},
   "source": [
    "# Calculate unknown unknowns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d576f-29dd-4c2e-bf6d-6f9cb29a3162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_dataset = calculate_unknowns(\n",
    "    cardholder_merchant, \n",
    "    cardholder_all, \n",
    "    all_merchant, \n",
    "    all_all\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36200636-a218-4322-8b6c-8538fc620990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f16808-0d8b-4c6f-9e29-942d808bafdc",
   "metadata": {},
   "source": [
    "## CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507ccdf-bb21-4b5f-83b7-c452182e1ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_complete = complete_dataset['sum_spend'].sum()\n",
    "sum_all = all_all['sum_spend'].sum()\n",
    "sum_difference = round(sum_all - sum_complete)\n",
    "if sum_difference != 0:\n",
    "    print(f'''FAILED. \n",
    "    There is a difference between the sum of the complete dataset and the original all_all data. \n",
    "    The difference is: {sum_difference}''')\n",
    "else: \n",
    "    print(f'''PASSED.\n",
    "    the sums of the complete dataset and all_all dataset match (to the nearest integer)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb770db-ff01-43f2-b414-470b6c3f3e7f",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bedff5-070e-4f7c-8d01-0ad8ebbfa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create folder\n",
    "path = '/home/jupyter/ft_articles/outputs/article_march_2024/'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(\"Directory created successfully!\")\n",
    "else:\n",
    "    print(\"Directory already exists!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c66680-be36-419a-85cb-1546e6920805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (sum_difference == 0):\n",
    "    complete_dataset.to_csv(path + f'DO_NOT_EXPORT_FROM_GCP_{location_level}_{time_period}_spend.csv', index = False)\n",
    "else:\n",
    "    print('''NOT SAVED\n",
    "    sum all_all != sum complete_dataset.\n",
    "    INVESTIGATE THIS ISSUE AND MAKE SURE THE SUMS EQUAL EACH OTHER BEFORE SAVING!!!''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace22a3e-bb14-449d-9b56-055a334fcf3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unknowns Stats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac9d57-e266-4899-b591-2b97c08146b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_unknown_stats(cardholder_merchant, all_all, complete_dataset):\n",
    "    cardholder_unknown_original = cardholder_merchant[\n",
    "        (cardholder_merchant['cardholder_location'] == 'UNKNOWN')\n",
    "        & (cardholder_merchant['merchant_location'] != 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "    \n",
    "    cardholder_unknown_complete = complete_dataset[\n",
    "        (complete_dataset['cardholder_location'] == 'UNKNOWN')\n",
    "        & (complete_dataset['merchant_location'] != 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "\n",
    "    merchant_unknown_original = cardholder_merchant[\n",
    "        (cardholder_merchant['merchant_location'] == 'UNKNOWN')\n",
    "        & (cardholder_merchant['cardholder_location'] != 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "    \n",
    "    merchant_unknown_complete = complete_dataset[\n",
    "        (complete_dataset['merchant_location'] == 'UNKNOWN')\n",
    "        & (complete_dataset['cardholder_location'] != 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "\n",
    "    both_unknown_original = cardholder_merchant[\n",
    "        (cardholder_merchant['cardholder_location'] == 'UNKNOWN')\n",
    "        & (cardholder_merchant['merchant_location'] == 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "    \n",
    "    both_unknown_complete = complete_dataset[\n",
    "        (complete_dataset['cardholder_location'] == 'UNKNOWN')\n",
    "        & (complete_dataset['merchant_location'] == 'UNKNOWN')\n",
    "    ]['sum_spend'].sum()\n",
    "      \n",
    "    sum_all_unknowns_original = (\n",
    "        cardholder_unknown_original\n",
    "        + merchant_unknown_original\n",
    "        + both_unknown_original\n",
    "    )\n",
    "    \n",
    "    sum_all_unknowns_complete = (\n",
    "        cardholder_unknown_complete\n",
    "        + merchant_unknown_complete\n",
    "        + both_unknown_complete\n",
    "    )\n",
    "    sum_unknown_unknowns = (\n",
    "        all_all['sum_spend'].sum() \n",
    "        - cardholder_merchant['sum_spend'].sum()\n",
    "    )   \n",
    "    \n",
    "    perc_cardholder_unknown_original = (\n",
    "        cardholder_unknown_original /\n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    perc_cardholder_unknown_complete = (\n",
    "       cardholder_unknown_complete /\n",
    "       all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    \n",
    "    perc_merchant_unknown_original = (\n",
    "        merchant_unknown_original /\n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    perc_merchant_unknown_complete = (\n",
    "        merchant_unknown_complete /\n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    \n",
    "    perc_both_unknown_original = (\n",
    "        both_unknown_original /\n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    perc_both_unknown_complete = (\n",
    "        both_unknown_complete /\n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    \n",
    "    perc_all_unknowns_original = (\n",
    "        perc_cardholder_unknown_original\n",
    "        + perc_merchant_unknown_original\n",
    "        + perc_both_unknown_original\n",
    "    )\n",
    "    perc_all_unknowns_complete = (\n",
    "        perc_cardholder_unknown_complete\n",
    "        + perc_merchant_unknown_complete\n",
    "        + perc_both_unknown_complete\n",
    "    )\n",
    "   \n",
    "    perc_unknown_unknowns = (\n",
    "        sum_unknown_unknowns / \n",
    "        all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    perc_all_unknowns = (\n",
    "        (sum_all_unknowns_original + sum_unknown_unknowns)\n",
    "        / all_all['sum_spend'].sum() * 100\n",
    "    )\n",
    "    complete_dataset_unknowns = complete_dataset[\n",
    "        (complete_dataset['cardholder_location'] == 'UNKNOWN')\n",
    "        | (complete_dataset['merchant_location'] == 'UNKNOWN')\n",
    "    ]\n",
    "    total_perc_unknown = (\n",
    "        complete_dataset_unknowns['sum_spend'].sum() \n",
    "        / complete_dataset['sum_spend'].sum() * 100\n",
    "    )\n",
    "    print(f'Unknown Stats at a {location_level} and {time_period}ly breakdown:\\n')\n",
    "    print('Percentage unknown stats:')\n",
    "    print(f'    cardholder unknown:')\n",
    "    print(f'        original: {perc_cardholder_unknown_original:.2f}%')\n",
    "    print(f'        complete: {perc_cardholder_unknown_complete:.2f}%')      \n",
    "    print(f'    merchant unknown:')\n",
    "    print(f'        original: {perc_merchant_unknown_original:.2f}%')\n",
    "    print(f'        complete: {perc_merchant_unknown_complete:.2f}%')  \n",
    "    print(f'    both unknown:')\n",
    "    print(f'        original: {perc_both_unknown_original:.2f}%')\n",
    "    print(f'        complete: {perc_both_unknown_complete:.2f}%')\n",
    "    print(f'    all unknowns:')\n",
    "    print(f'        original: {perc_all_unknowns_original:.2f}%')\n",
    "    print(f'        complete: {perc_all_unknowns_complete:.2f}%%')\n",
    "    print('')\n",
    "    print(f'    unknown unknowns: {perc_unknown_unknowns:.2f}%')\n",
    "    print('')\n",
    "    print(f'''Total percentage unknown. This is any row which contains an unknown, \n",
    "    plus unknown unknowns, calculated using ORIGINAL DATA:''')\n",
    "    print(f'        {perc_all_unknowns:.2f}%')\n",
    "    print('')\n",
    "    print(f'''Total percentage unknown. This is any row which contains an unknown, \n",
    "    plus unknown unknowns, calculated using COMPLETE_DATASET:''')\n",
    "    print(f'        {total_perc_unknown:.2f}%')\n",
    "    print('')\n",
    "    print('Sum unknowns:')\n",
    "    print(f'    unknown cardholder location: £{cardholder_unknown_complete:,}')\n",
    "    print(f'    unknown merchant location: £{merchant_unknown_complete:,}')\n",
    "    print(f'    unknown cardholder and merchant location: £{both_unknown_complete:,}')\n",
    "    print(f'    all unknowns: £{sum_all_unknowns_complete:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298344b-b7d6-495a-a679-f080cf8bb22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_unknown_stats(cardholder_merchant, all_all, complete_dataset)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m116"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

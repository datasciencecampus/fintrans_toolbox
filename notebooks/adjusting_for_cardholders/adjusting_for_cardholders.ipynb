{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae908ae-868e-415c-8ede-962f0f0e3ddc",
   "metadata": {},
   "source": [
    "# Adjusting for cardholders\n",
    "\n",
    "The method created so far is to have an adjustment table for each table and then this is read in and joined to the table that you are working with allowing you to create an adjusted spend/transcations value.\n",
    "\n",
    "Further development will be required to see if we want to use one adjustment table or if we keep having seperate adjustment tables for each table. Moreover, how do we deal with different specifications, and the drop in cardholders over covid. These tables will have to be amended. \n",
    "\n",
    "The adjustment tables will be stored in fin_wip_notebook and read in accordingly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cde59-40ff-4024-95db-77a21ebd635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/home/jupyter\"\n",
    "import sys\n",
    "\n",
    "sys.path.append(project_path)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from fintrans_toolbox.src import bq_utils as bq\n",
    "from fintrans_toolbox.src import table_utils as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c2d6e-8ac0-4398-b009-b05819997401",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74c516-43f6-44b6-a5c9-9b392a7893db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to create our adjustment tables that we will bring in every time we want to create an adjusted value\n",
    "# we do one for each table and each month/quarter then join on the date\n",
    "\n",
    "# THE ADJUSTMENT TABLES will have to be amendended as they don't account for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9384f12-826a-41f9-9afc-e0e072db8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_rphst(df, time_period):\n",
    "    \"\"\"\n",
    "    Gets data from BigQuery and saves to Pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "       - df1: the dataframe of interest that you have read in\n",
    "       - table: which table the dataframe is on so we have a reference for adjustment table to bring in\n",
    "       - time_period: which time_period the dataframe is on so we have a reference for adjustment table to bring in\n",
    "    Returns:\n",
    "       - the dataframe with adjusted spend/transactions if that variable exists\n",
    "    \"\"\"\n",
    "    \n",
    "    if time_period in [\"Quarter\", \"quarter\", \"q\"]:\n",
    "        time_period = \"Quarter\"\n",
    "    if time_period in [\"Month\", \"month\", \"m\"]:\n",
    "        time_period = \"M\"\n",
    "        \n",
    "    client = bigquery.Client()\n",
    "    df_adj = t.read_retail_performance_high_streets_towns(\n",
    "                                                            client,\n",
    "                                                            time_period,\n",
    "                                                            cardholder_location_level=\"All\",\n",
    "                                                            merchant_location_level=\"All\",\n",
    "                                                            mcg=\"All\",\n",
    "                                                            cardholder_location=\"\",\n",
    "                                                            merchant_location=\"\",\n",
    "                                                        )\n",
    "\n",
    "    df_adj = t.create_date_time(df_adj)\n",
    "    df_adj = df_adj.sort_values(by = [\"time_period\" , \"date_time\"])\n",
    "\n",
    "    df_adj[\"index\"] = df_adj.groupby([\"time_period\"])[\n",
    "        \"cardholders\"\n",
    "    ].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "    \n",
    "#    df_adj = bq.read_full_bq_table(\n",
    " #       client,\n",
    " #       f\"ons-fintrans-analysis-prod.fin_wip_notebook.\",\n",
    " #   )\n",
    "    # link on datetime first\n",
    "    try:\n",
    "        df1 = df.merge(\n",
    "            df_adj[[\"date_time\", \"index\"]], on=\"date_time\", how=\"left\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"{e}: using time_period_value instead of date_time, consider converting to date_time\"\n",
    "        )\n",
    "        df1 = df.merge(\n",
    "            df_adj[[\"time_period_value\", \"index\"]],\n",
    "            on=\"time_period_value\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    try:\n",
    "        df1[\"idx_spend\"] = df1[\"spend\"] / df1[\"index\"]\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "    try:\n",
    "        df1[\"idx_transactions\"] = df1[\"transactions\"] / df1[\"index\"]\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "\n",
    "    return df1\n",
    "## TODO: ADD catch incase merge creates extra rows. Should be 1to1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6717e9-cdb0-4f3f-835d-afcf52061761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test adjust rphst\n",
    "df = t.read_retail_performance_high_streets_towns(\n",
    "    client,\n",
    "    time_period=\"Month\",\n",
    "    cardholder_location_level=\"POSTAL_AREA\",\n",
    "    merchant_location_level=\"All\",\n",
    "    mcg=\"All\",\n",
    "    cardholder_location=\"\",\n",
    "    merchant_location=\"\",\n",
    ")\n",
    "\n",
    "df2 = adjusted_rphst(df, \"Month\")\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93307c-0254-40e2-a230-4b7996fbb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph actual and adjusted spend\n",
    "df3 = df2.loc[df2.cardholder_location == \"LD\"]\n",
    "plt.plot(df3[\"date_time\"],df3[\"spend\"])\n",
    "plt.plot(df3[\"date_time\"], df3[\"idx_spend\"])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490135c-2301-4dab-8ea8-8e9b978c2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_spoc(df, \n",
    "                  time_period = \"\", \n",
    "                  cardholder_origin = \"\",\n",
    "                  merchant_channel = \"\"):\n",
    "    \"\"\"\n",
    "    Gets data from BigQuery and saves to Pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "       - df: the dataframe to be adjusted\n",
    "       - time_period: which time_period the dataframe is on so we have a reference for adjustment table to bring in. Defaults to any, where month and quarter will br included.\n",
    "       - cardholder_origin: \"All\", \"International Cardholder\" or \"United Kingdom\". Defaults to any, where all of these will be included.\n",
    "       - Merchant channel: \"All\", \"Online\" or \"Face to Face\". Defaults to any, where all of these will be included.\n",
    "    Returns:\n",
    "       - the dataframe with adjusted spend/transactions if that variable exists\n",
    "    \"\"\"\n",
    "    \n",
    "    if time_period in [\"Quarter\", \"quarter\", \"q\"]:\n",
    "        time_period = \"Quarter\"\n",
    "    if time_period in [\"Month\", \"month\", \"m\"]:\n",
    "        time_period = \"Month\"\n",
    "    \n",
    "    sql = \"SELECT * FROM `ons-fintrans-data-prod.fintrans_visa.spend_origin_and_channel` WHERE (cardholder_origin = 'UNITED KINGDOM' and cardholder_location = 'All' and mcg = 'All') or (cardholder_origin = 'International Cardholder'  and mcg = 'All') or (cardholder_origin = 'All'  and mcg = 'All')\"\n",
    "    client = bigquery.Client()\n",
    "    df_adj = bq.read_bq_table_sql(client, sql)\n",
    "    \n",
    "    if time_period != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.time_period.str.upper() == time_period.upper())]\n",
    "    elif cardholder_origin != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.cardholder_origin.str.upper() == cardholder_origin.upper())]\n",
    "    elif merchant_channel != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.merchant_channel.str.upper() == merchant_channel.upper())]\n",
    "    else: pass\n",
    "        \n",
    "        \n",
    "    df_adj = df_adj.groupby(['time_period', \n",
    "                     'time_period_value', \n",
    "                     'cardholder_origin',    \n",
    "                     'cardholder_origin_country', \n",
    "                     'mcg', \n",
    "                     'mcc', \n",
    "                     'merchant_channel']).sum(['spend', 'transactions', 'cardholders']).reset_index()\n",
    "\n",
    "    df_adj = t.create_date_time(df_adj)\n",
    "    df_adj = df_adj.sort_values(by = [\"cardholder_origin\",\"cardholder_origin_country\", \"merchant_channel\",\"time_period\" , \"date_time\"])\n",
    "\n",
    "    df_adj[\"index\"] = df_adj.groupby([\"cardholder_origin\",\"cardholder_origin_country\",\"merchant_channel\",\"time_period\"])[\n",
    "        \"cardholders\"\n",
    "    ].transform(lambda x: x / x.iloc[0])\n",
    "    \n",
    "    df_adj.loc[df_adj['cardholder_origin'] == \"UNITED KINGDOM\", 'merged_country'] = \"UNITED KINGDOM\"\n",
    "    df_adj.loc[df_adj['cardholder_origin'] != \"UNITED KINGDOM\", 'merged_country'] = df_adj.cardholder_origin_country\n",
    "    \n",
    "    if set([ \"cardholder_origin_country\",\"cardholder_origin\"]).issubset(df.columns):\n",
    "            df.loc[df['cardholder_origin'] == \"UNITED KINGDOM\", 'merged_country'] = \"UNITED KINGDOM\"\n",
    "            df.loc[df['cardholder_origin'] != \"UNITED KINGDOM\", 'merged_country'] = df.cardholder_origin_country  \n",
    "            df = df.drop(columns = [ \"cardholder_origin_country\",\"cardholder_origin\"])\n",
    "    elif cardholder_origin == \"\":\n",
    "        print(\"cardholder origin needs to be set if cardholder_origin_country and cardholder_origin are not on the dataframe\")\n",
    "    else: df = df.assign(merged_country = cardholder_origin)\n",
    " \n",
    "    # If cardholder origin \"internation\" and cardholder issueing country doesn't exist, fail\n",
    "    if cardholder_origin == \"International Cardholder\" and not any(df.columns == \"cardholder_origin_country\"):\n",
    "        print(\"cardholder_origin = 'International Cardholder' but cardholder_origin_country column does not exist. Need to match on country for international\")\n",
    "        \n",
    "    elif (merchant_channel == \"\" and not any(df_adj.columns == \"merchant_channel\")):\n",
    "        print(\"merchant channel is not specified, but there is no column for merchant channel so merge will not work\")\n",
    "    \n",
    "    else:\n",
    "        cols = ['time_period','merged_country','merchant_channel']\n",
    "        merge_on = list(set(cols) & set(df_adj.columns))\n",
    "        # link on datetime, cardholder origin, issuing country and merchant channel first\n",
    "    try:\n",
    "              df1 = df.merge(df_adj[[\"date_time\"] + merge_on + [\"index\"]], on = [\"date_time\"] + merge_on ,  how=\"left\" )\n",
    "              print(f\"Merging on date_time, {merge_on}\")\n",
    "    except Exception as e:\n",
    "                    print(\n",
    "                        f\"{e}: using time_period_value instead of date_time, consider converting to date_time\"\n",
    "                    )\n",
    "                    print(f\"Merging on time_period_value, {merge_on}\")\n",
    "                    df1 = df.merge(df_adj[[\"time_period_value\"] + merge_on + [\"index\"]], on = [\"time_period_value\"] + merge_on ,  how=\"left\" )\n",
    "                          \n",
    "    try:\n",
    "           df1[\"idx_spend\"] = df1[\"spend\"] / df1[\"index\"]\n",
    "    except Exception as e:\n",
    "            print(f\"{e}\")\n",
    "    try:\n",
    "           df1[\"idx_transactions\"] = df1[\"transactions\"] / df1[\"index\"]\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "        \n",
    "    if len(df1) != len(df):\n",
    "        print(\"output table is different legth to input table, check merge\")\n",
    "\n",
    "    return df1\n",
    "    ## TODO: ADD catch incase merge creates extra rows. Should be 1to1\n",
    "    ## TODO: ADD catch incase merge creates extra rows. Should be 1to1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bdaa4-3418-4126-a637-c4b479b5fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_on = list(set(cols) & set(df_adj.columns))\n",
    "merge_on\n",
    "\n",
    "df = df.assign(merged_country = cardholder_origin)\n",
    "df\n",
    "#df1 = df.merge(df_adj[[\"time_period_value\"] + merge_on + [\"index\"]], on = [\"time_period_value\"] + merge_on ,  how=\"left\" )\n",
    "\n",
    "#df1 = df.merge(df_adj[[\"date_time\"] + merge_on + [\"index\"]], on = [\"date_time\"] + merge_on ,  how=\"left\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4168899-4998-402f-899d-0caf913f0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #merchant_channel = \"Online\"\n",
    "    #cardholder_origin = \"UNITED KINGDOM\"\n",
    "    sql = \"SELECT * FROM `ons-fintrans-data-prod.fintrans_visa.spend_origin_and_channel` limit 500000 \"\n",
    "    df = bq.read_bq_table_sql(client, sql)\n",
    "    client = bigquery.Client()\n",
    "    df = df.loc[df.cardholder_origin == \"International Cardholder\"]\n",
    "    df = df.drop(columns =[\"cardholder_origin\", \"cardholder_origin_country\"])\n",
    "\n",
    "    df1 = adjusted_spoc(df, merchant_channel = \"Online\",cardholder_origin = \"International Cardholder\")\n",
    "    df1\n",
    "    \n",
    "    #df1 = df1.loc[df1.merged_country == \"CHILE\"]\n",
    "    #df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc470141-ec90-4969-93ee-2d9c711a9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    merchant_channel = \"Online\"\n",
    "    cardholder_origin = \"International Cardholder\"\n",
    "    sql = \"SELECT * FROM `ons-fintrans-data-prod.fintrans_visa.spend_origin_and_channel` limit 500000 \"\n",
    "    df = bq.read_bq_table_sql(client, sql)\n",
    "    client = bigquery.Client()\n",
    "    df = df.loc[df.cardholder_origin == \"UNITED KINGDOM\"]\n",
    "    df = df.drop(columns =[\"cardholder_origin\", \"cardholder_origin_country\"]) \n",
    "    if time_period in [\"Quarter\", \"quarter\", \"q\"]:\n",
    "        time_period = \"Quarter\"\n",
    "    if time_period in [\"Month\", \"month\", \"m\"]:\n",
    "        time_period = \"Month\"\n",
    "    \n",
    "    sql = \"SELECT * FROM `ons-fintrans-data-prod.fintrans_visa.spend_origin_and_channel` WHERE (cardholder_origin = 'UNITED KINGDOM' and cardholder_location = 'All' and mcg = 'All') or (cardholder_origin = 'International Cardholder'  and mcg = 'All') or (cardholder_origin = 'All'  and mcg = 'All')\"\n",
    "    client = bigquery.Client()\n",
    "    df_adj = bq.read_bq_table_sql(client, sql)\n",
    "    \n",
    "    if time_period != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.time_period.str.upper() == time_period.upper())]\n",
    "    elif cardholder_origin != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.cardholder_origin.str.upper() == cardholder_origin.upper())]\n",
    "    elif merchant_channel != \"\":\n",
    "        df_adj = df_adj.loc[(df_adj.merchant_channel.str.upper() == merchant_channel.upper())]\n",
    "        \n",
    "        \n",
    "    df_adj = df_adj.groupby(['time_period', \n",
    "                     'time_period_value', \n",
    "                     'cardholder_origin',    \n",
    "                     'cardholder_origin_country', \n",
    "                     'mcg', \n",
    "                     'mcc', \n",
    "                     'merchant_channel']).sum(['spend', 'transactions', 'cardholders']).reset_index()\n",
    "\n",
    "    df_adj = t.create_date_time(df_adj)\n",
    "    df_adj = df_adj.sort_values(by = [\"cardholder_origin\",\"cardholder_origin_country\", \"merchant_channel\",\"time_period\" , \"date_time\"])\n",
    "\n",
    "    df_adj[\"index\"] = df_adj.groupby([\"cardholder_origin\",\"cardholder_origin_country\",\"merchant_channel\",\"time_period\"])[\n",
    "        \"cardholders\"\n",
    "    ].transform(lambda x: x / x.iloc[0])\n",
    "    \n",
    "    df_adj.loc[df_adj['cardholder_origin'] == \"UNITED KINGDOM\", 'merged_country'] = \"UNITED KINGDOM\"\n",
    "    df_adj.loc[df_adj['cardholder_origin'] != \"UNITED KINGDOM\", 'merged_country'] = df_adj.cardholder_origin_country\n",
    "    \n",
    "    if set([ \"cardholder_origin_country\",\"cardholder_origin\"]).issubset(df.columns):\n",
    "            df.loc[df['cardholder_origin'] == \"UNITED KINGDOM\", 'merged_country'] = \"UNITED KINGDOM\"\n",
    "            df.loc[df['cardholder_origin'] != \"UNITED KINGDOM\", 'merged_country'] = df.cardholder_origin_country  \n",
    "            df = df.drop(columns = [ \"cardholder_origin_country\",\"cardholder_origin\"])\n",
    "    elif cardholder_origin == \"\":\n",
    "        print(\"cardholder origin needs to be set if cardholder_origin_country and cardholder_origin are not on the dataframe\")\n",
    "    else: df = df.assign(merged_country = cardholder_origin)\n",
    " \n",
    "    # If cardholder origin \"international\" and cardholder issueing country doesn't exist, fail\n",
    "    if cardholder_origin == \"International Cardholder\" and not any(df.columns == \"cardholder_origin_country\"):\n",
    "        print(\"cardholder_origin = 'International Cardholder' but cardholder_origin_country column does not exist. Need to match on country for international\")\n",
    "        \n",
    "    elif (merchant_channel == \"\" and not any(df_adj.columns == \"merchant_channel\")):\n",
    "        print(\"merchant channel is not specified, but there is no column for merchant channel so merge will not work\")\n",
    "    \n",
    "    else:\n",
    "        cols = ['time_period','merged_country','merchant_channel']\n",
    "        merge_on = list(set(cols) & set(df_adj.columns))\n",
    "        # link on datetime, cardholder origin, issuing country and merchant channel first\n",
    "    try:\n",
    "              df1 = df.merge(df_adj[[\"date_time\"] + merge_on + [\"index\"]], on = [\"date_time\"] + merge_on ,  how=\"left\" )\n",
    "              print(f\"Merging on date_time, {merge_on}\")\n",
    "    except Exception as e:\n",
    "                    print(\n",
    "                        f\"{e}: using time_period_value instead of date_time, consider converting to date_time\"\n",
    "                    )\n",
    "                    print(f\"Merging on time_period_value, {merge_on}\")\n",
    "                    df1 = df.merge(df_adj[[\"time_period_value\"] + merge_on + [\"index\"]], on = [\"time_period_value\"] + merge_on ,  how=\"left\" )\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-2.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-2:m108"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
